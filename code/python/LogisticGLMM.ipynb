{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import LinearResponseVariationalBayes as vb\n",
    "import LogisticGLMM_lib as logit_glmm\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "from LinearResponseVariationalBayes.SparseObjectives import \\\n",
    "    Objective, pack_csr_matrix\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import autograd\n",
    "\n",
    "import copy\n",
    "from scipy import optimize\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "import time\n",
    "\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['mu_prior_mean', 'tau_prior_beta', 'beta_prior_info', 'tau_prior_alpha', 'beta_prior_mean', 'y_group', 'N', 'x', 'y', 'K', 'NG', 'mu_prior_info'])\n",
      "0.205306400805\n"
     ]
    }
   ],
   "source": [
    "# Load data saved by stan_results_to_json.R and run_stan.R in LRVBLogitGLMM.\n",
    "\n",
    "simulate_data = False\n",
    "\n",
    "if not simulate_data:\n",
    "    #analysis_name = 'simulated_data_small'\n",
    "    analysis_name = 'criteo_subsampled'\n",
    "\n",
    "    data_dir = os.path.join(os.environ['GIT_REPO_LOC'],\n",
    "                            'VariationalBayesPythonWorkbench/Models/LogisticGLMM/data')\n",
    "    json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "    y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "    \n",
    "    K = x_mat.shape[1]\n",
    "    NG = np.max(y_g_vec) + 1\n",
    "\n",
    "else:\n",
    "    # Generate data\n",
    "    N = 200     # observations per group\n",
    "    K = 5      # dimension of regressors\n",
    "    NG = 200      # number of groups\n",
    "\n",
    "    true_beta = np.array(range(5))\n",
    "    true_beta = true_beta - np.mean(true_beta)\n",
    "    true_mu = 0.\n",
    "    true_tau = 40.0\n",
    "\n",
    "    x_mat, y_g_vec, y_vec, true_rho, true_u = \\\n",
    "        logit_glmm.simulate_data(N, NG, true_beta, true_mu, true_tau)\n",
    "    prior_par = logit_glmm.get_default_prior_params(K)\n",
    "    glmm_par = logit_glmm.get_glmm_parameters(K=K, NG=NG)\n",
    "\n",
    "timer = obj_lib.Timer()\n",
    "print(np.mean(y_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "# Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "# seem worth explaining in the paper.\n",
    "\n",
    "logit_glmm.initialize_glmm_pars(glmm_par)\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_draws =  3\n",
      "\tFunction time: 0.014626581300399266\n",
      "\tGrad time: 0.05417204719997244\n",
      "\tHessian vector product time: 0.12540567840042058\n",
      "\tPrior hess time:  0.07785177230834961\n"
     ]
    }
   ],
   "source": [
    "model = logit_glmm.LogisticGLMM(glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=4)\n",
    "model.get_e_log_prior()\n",
    "model.get_log_lik()\n",
    "model.get_entropy()\n",
    "\n",
    "model.objective.fun_free(free_par_vec)\n",
    "\n",
    "import timeit\n",
    "\n",
    "time_num = 10\n",
    "\n",
    "num_draws = 3\n",
    "model.set_gh_points(num_draws)\n",
    "print('num_draws = ', num_draws)\n",
    "print('\\tFunction time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tGrad time:', \n",
    "      timeit.timeit(lambda: model.objective.fun_free_grad(free_par_vec), number=time_num) / time_num)\n",
    "\n",
    "print('\\tHessian vector product time:',\n",
    "      timeit.timeit(lambda: model.objective.fun_free_hvp(\n",
    "          free_par_vec, free_par_vec + 1), number=time_num) / time_num)\n",
    "\n",
    "prior_vec = model.prior_par.get_vector()\n",
    "prior_hess_time = time.time()\n",
    "model.get_prior_hess(prior_vec, init_par_vec)\n",
    "prior_hess_time = time.time() - prior_hess_time\n",
    "print('\\tPrior hess time: ', prior_hess_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region.\n",
      "Iter  0  value:  161754.842095\n",
      "Iter  5  value:  54504.7996458\n",
      "Iter  10  value:  30461.6617634\n",
      "Iter  15  value:  28137.0474103\n",
      "Iter  20  value:  24034.2014815\n",
      "Iter  25  value:  23384.2986216\n",
      "Iter  30  value:  23303.4580863\n",
      "Iter  35  value:  23294.0949073\n",
      "Iter  40  value:  23287.6079308\n",
      "Iter  45  value:  23287.5932529\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 23287.593253\n",
      "         Iterations: 45\n",
      "         Function evaluations: 46\n",
      "         Gradient evaluations: 46\n",
      "         Hessian evaluations: 0\n",
      "vb_time: 64.20108199119568 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "num_gh_points = 4\n",
    "timer.tic()\n",
    "vb_opt = model.tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "timer.toc('vb_time')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Group 0 of 4999.\n",
      "Group 100 of 4999.\n",
      "Group 200 of 4999.\n",
      "Group 300 of 4999.\n",
      "Group 400 of 4999.\n",
      "Group 500 of 4999.\n",
      "Group 600 of 4999.\n",
      "Group 700 of 4999.\n",
      "Group 800 of 4999.\n",
      "Group 900 of 4999.\n",
      "Group 1000 of 4999.\n",
      "Group 1100 of 4999.\n",
      "Group 1200 of 4999.\n",
      "Group 1300 of 4999.\n",
      "Group 1400 of 4999.\n",
      "Group 1500 of 4999.\n",
      "Group 1600 of 4999.\n",
      "Group 1700 of 4999.\n",
      "Group 1800 of 4999.\n",
      "Group 1900 of 4999.\n",
      "Group 2000 of 4999.\n",
      "Group 2100 of 4999.\n",
      "Group 2200 of 4999.\n",
      "Group 2300 of 4999.\n",
      "Group 2400 of 4999.\n",
      "Group 2500 of 4999.\n",
      "Group 2600 of 4999.\n",
      "Group 2700 of 4999.\n",
      "Group 2800 of 4999.\n",
      "Group 2900 of 4999.\n",
      "Group 3000 of 4999.\n",
      "Group 3100 of 4999.\n",
      "Group 3200 of 4999.\n",
      "Group 3300 of 4999.\n",
      "Group 3400 of 4999.\n",
      "Group 3500 of 4999.\n",
      "Group 3600 of 4999.\n",
      "Group 3700 of 4999.\n",
      "Group 3800 of 4999.\n",
      "Group 3900 of 4999.\n",
      "Group 4000 of 4999.\n",
      "Group 4100 of 4999.\n",
      "Group 4200 of 4999.\n",
      "Group 4300 of 4999.\n",
      "Group 4400 of 4999.\n",
      "Group 4500 of 4999.\n",
      "Group 4600 of 4999.\n",
      "Group 4700 of 4999.\n",
      "Group 4800 of 4999.\n",
      "Group 4900 of 4999.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/autograd/autograd/core.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 81.17607235908508 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "model.glmm_par.set_free(opt_x)\n",
    "\n",
    "timer.tic()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = model.get_sparse_free_hessian(opt_x, print_every_n=100)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = model.get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = model.moment_wrapper.get_moment_jacobian(opt_x)\n",
    "timer.toc('hess_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving systems...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: CholmodTypeConversionWarning: converting matrix of class csr_matrix to CSC format\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse_time: 5.8676300048828125 seconds\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Solving systems...\\n')\n",
    "timer.tic()\n",
    "from scikits.sparse.cholmod import cholesky\n",
    "kl_hess_chol = cholesky(kl_hess)\n",
    "kl_inv_moment_jac = kl_hess_chol.solve_A(moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, kl_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, kl_inv_moment_jac).T\n",
    "timer.toc('inverse_time')\n",
    "print('Done\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if False:\n",
    "    old_inv_time = time.time()\n",
    "    kl_inv_moment_jac_solve = sp.sparse.linalg.spsolve(kl_hess, moment_jac.T)\n",
    "    old_inv_time = time.time() - old_inv_time\n",
    "\n",
    "    print('Difference:', np.linalg.norm(kl_inv_moment_jac_solve - kl_inv_moment_jac))\n",
    "    print('Old time: ', old_inv_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  20\n",
      "Iter  40\n",
      "Iter  60\n",
      "Iter  80\n",
      "cg_row_time: 11.147464275360107 seconds\n",
      "Number of iterations:  84\n",
      "7.2349356726e-07\n"
     ]
    }
   ],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return model.objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "timer.tic()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "timer.toc('cg_row_time')\n",
    "\n",
    "num_cg_iterations = optimum_hvp.iter\n",
    "print('Number of iterations: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - kl_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/VariationalBayesPythonWorkbench/Models/LogisticGLMM/data/criteo_subsampled_python_vb_results.pkl\n",
      "\n",
      "\n",
      "DONE.\n"
     ]
    }
   ],
   "source": [
    "if not simulate_data:\n",
    "    # Write the result to a pickle file for use in subsequent analysis.\n",
    "    model.glmm_par.set_free(opt_x)\n",
    "\n",
    "    run_name = 'production'\n",
    "    \n",
    "    pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "    pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "    # Unlike with JSON, numpy arrays can be pickled.\n",
    "    # Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "    pickle_result_dict = logit_glmm.get_pickle_dictionary(model, kl_hess, moment_jac)\n",
    "    pickle_result_dict.update(\n",
    "                         { 'run_name': run_name,\n",
    "                            'vb_time': timer.time_dict['vb_time'],\n",
    "                            'hess_time': timer.time_dict['hess_time'],\n",
    "                            'inverse_time': timer.time_dict['inverse_time'],\n",
    "                            'cg_row_time': timer.time_dict['cg_row_time'],\n",
    "                            'num_cg_iterations': num_cg_iterations,\n",
    "                            'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                            'kl_inv_moment_jac': kl_inv_moment_jac,\n",
    "                            'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                            'log_prior_hess': np.squeeze(log_prior_hess) })\n",
    "\n",
    "    # Pickle dictionary.\n",
    "    pickle.dump(pickle_result_dict, pickle_output)\n",
    "    pickle_output.close()\n",
    "    \n",
    "    print(pickle_output_filename)\n",
    "\n",
    "\n",
    "print('\\n\\nDONE.')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
