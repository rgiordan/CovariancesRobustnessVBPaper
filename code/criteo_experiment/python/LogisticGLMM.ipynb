{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/autograd/core.py:290: UserWarning: \n",
      "The defvjp method is deprecated. See the update guide and tutorial:\n",
      "https://github.com/HIPS/autograd/blob/master/docs/updateguide.md\n",
      "https://github.com/HIPS/autograd/blob/master/docs/tutorial.md\n",
      "  warnings.warn(deprecation_msg)\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import json\n",
    "\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import logistic_glmm_lib as logit_glmm\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "#from scikits.sparse.cholmod import cholesky\n",
    "from sksparse.cholmod import cholesky\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['NG', 'N', 'K', 'y_group', 'y', 'x', 'beta_prior_mean', 'beta_prior_info', 'mu_prior_mean', 'mu_prior_info', 'tau_prior_alpha', 'tau_prior_beta'])\n"
     ]
    }
   ],
   "source": [
    "#analysis_name = 'simulated_data_small'\n",
    "analysis_name = 'criteo_subsampled'\n",
    "\n",
    "git_dir_cmd = subprocess.run(\n",
    "    ['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE)\n",
    "assert git_dir_cmd.returncode == 0\n",
    "git_dir = git_dir_cmd.stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "data_dir = os.path.join(git_dir, 'code/criteo_experiment/data')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "\n",
    "num_gh_points = 4\n",
    "\n",
    "timer = obj_lib.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "# Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "# seem worth explaining in the paper.\n",
    "\n",
    "logit_glmm.initialize_glmm_pars(glmm_par)\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "prior_par_vec = prior_par.get_vector()\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(\n",
    "    glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=num_gh_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region.\n",
      "Iter  0  value:  159113.21321886263\n",
      "Iter  5  value:  53225.833558938175\n",
      "Iter  10  value:  29660.28837238788\n",
      "Iter  15  value:  27225.66997816494\n",
      "Iter  20  value:  25130.852267518603\n",
      "Iter  25  value:  22878.910190898812\n",
      "Iter  30  value:  22636.16679943079\n",
      "Iter  35  value:  22604.410264763243\n",
      "Iter  40  value:  22595.11385866494\n",
      "Iter  45  value:  22585.27377621851\n",
      "Iter  50  value:  22585.265595576548\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 22585.265596\n",
      "         Iterations: 50\n",
      "         Function evaluations: 51\n",
      "         Gradient evaluations: 51\n",
      "         Hessian evaluations: 463\n",
      "vb_time: 89.77029991149902 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "timer.tic()\n",
    "vb_opt = model.tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "timer.toc('vb_time')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Group 0 of 4999.\n",
      "Group 100 of 4999.\n",
      "Group 200 of 4999.\n",
      "Group 300 of 4999.\n",
      "Group 400 of 4999.\n",
      "Group 500 of 4999.\n",
      "Group 600 of 4999.\n",
      "Group 700 of 4999.\n",
      "Group 800 of 4999.\n",
      "Group 900 of 4999.\n",
      "Group 1000 of 4999.\n",
      "Group 1100 of 4999.\n",
      "Group 1200 of 4999.\n",
      "Group 1300 of 4999.\n",
      "Group 1400 of 4999.\n",
      "Group 1500 of 4999.\n",
      "Group 1600 of 4999.\n",
      "Group 1700 of 4999.\n",
      "Group 1800 of 4999.\n",
      "Group 1900 of 4999.\n",
      "Group 2000 of 4999.\n",
      "Group 2100 of 4999.\n",
      "Group 2200 of 4999.\n",
      "Group 2300 of 4999.\n",
      "Group 2400 of 4999.\n",
      "Group 2500 of 4999.\n",
      "Group 2600 of 4999.\n",
      "Group 2700 of 4999.\n",
      "Group 2800 of 4999.\n",
      "Group 2900 of 4999.\n",
      "Group 3000 of 4999.\n",
      "Group 3100 of 4999.\n",
      "Group 3200 of 4999.\n",
      "Group 3300 of 4999.\n",
      "Group 3400 of 4999.\n",
      "Group 3500 of 4999.\n",
      "Group 3600 of 4999.\n",
      "Group 3700 of 4999.\n",
      "Group 3800 of 4999.\n",
      "Group 3900 of 4999.\n",
      "Group 4000 of 4999.\n",
      "Group 4100 of 4999.\n",
      "Group 4200 of 4999.\n",
      "Group 4300 of 4999.\n",
      "Group 4400 of 4999.\n",
      "Group 4500 of 4999.\n",
      "Group 4600 of 4999.\n",
      "Group 4700 of 4999.\n",
      "Group 4800 of 4999.\n",
      "Group 4900 of 4999.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/autograd/tracer.py:14: UserWarning: Output seems independent of input.\n",
      "  warnings.warn(\"Output seems independent of input.\")\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'row'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-02d26991b1db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'KL Hessian...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mkl_hess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sparse_free_hessian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Log prior Hessian...\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/python/logistic_glmm_lib.py\u001b[0m in \u001b[0;36mget_sparse_free_hessian\u001b[0;34m(self, free_par, print_every_n)\u001b[0m\n\u001b[1;32m    399\u001b[0m         return get_free_hessian(\n\u001b[1;32m    400\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_par\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             print_every_n=print_every_n)\n\u001b[0m\u001b[1;32m    402\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sparse_weight_free_jacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_par\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every_n\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/python/logistic_glmm_lib.py\u001b[0m in \u001b[0;36mget_free_hessian\u001b[0;34m(glmm_model, group_model, global_model, free_par, vector_hess, print_every_n)\u001b[0m\n\u001b[1;32m    735\u001b[0m         \u001b[0mglmm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglmm_par\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_free\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m         \u001b[0mvector_grad\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 737\u001b[0;31m         vector_hess)\n\u001b[0m\u001b[1;32m    738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/Parameters.py\u001b[0m in \u001b[0;36mconvert_vector_to_free_hessian\u001b[0;34m(param, free_val, vector_grad, vector_hess)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_free\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0mfree_to_vec_jacobian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_to_vector_jac\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m     \u001b[0mfree_to_vec_hessian\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_to_vector_hess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;31m# Accumulate the third order terms, which are sparse.  Use the fact\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/ParameterDictionary.py\u001b[0m in \u001b[0;36mfree_to_vector_hess\u001b[0;34m(self, free_val)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             free_offset = free_to_vector_hess_offset(\n\u001b[0;32m---> 80\u001b[0;31m                 param, free_val, hessians, free_offset, full_shape)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessians\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/Parameters.py\u001b[0m in \u001b[0;36mfree_to_vector_hess_offset\u001b[0;34m(param, free_vec, hessians, free_offset, full_shape)\u001b[0m\n\u001b[1;32m    353\u001b[0m     param, free_vec, hessians, free_offset, full_shape):\n\u001b[1;32m    354\u001b[0m     \u001b[0mfree_slice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfree_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m     \u001b[0mhess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_to_vector_hess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfree_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfree_slice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvec_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         hessians.append(offset_sparse_matrix(\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/ParameterDictionary.py\u001b[0m in \u001b[0;36mfree_to_vector_hess\u001b[0;34m(self, free_val)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             free_offset = free_to_vector_hess_offset(\n\u001b[0;32m---> 80\u001b[0;31m                 param, free_val, hessians, free_offset, full_shape)\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhessians\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/Parameters.py\u001b[0m in \u001b[0;36mfree_to_vector_hess_offset\u001b[0;34m(param, free_vec, hessians, free_offset, full_shape)\u001b[0m\n\u001b[1;32m    356\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mvec_ind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m         hessians.append(offset_sparse_matrix(\n\u001b[0;32m--> 358\u001b[0;31m             hess[vec_ind], (free_offset, free_offset), full_shape))\n\u001b[0m\u001b[1;32m    359\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfree_offset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mparam\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfree_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/git_repos/tests/CovariancesRobustnessVBPaper/code/criteo_experiment/venv/lib/python3.6/site-packages/LinearResponseVariationalBayes/Parameters.py\u001b[0m in \u001b[0;36moffset_sparse_matrix\u001b[0;34m(spmat, offset_shape, full_shape)\u001b[0m\n\u001b[1;32m    344\u001b[0m     return coo_matrix(\n\u001b[1;32m    345\u001b[0m         (spmat.data,\n\u001b[0;32m--> 346\u001b[0;31m          (spmat.row + offset_shape[0], spmat.col + offset_shape[1])),\n\u001b[0m\u001b[1;32m    347\u001b[0m          shape=full_shape)\n\u001b[1;32m    348\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'row'"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "model.glmm_par.set_free(opt_x)\n",
    "\n",
    "timer.tic()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = model.get_sparse_free_hessian(opt_x, print_every_n=100)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = model.get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = model.moment_wrapper.get_moment_jacobian(opt_x)\n",
    "timer.toc('hess_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Solving systems...\\n')\n",
    "timer.tic()\n",
    "from scikits.sparse.cholmod import cholesky\n",
    "kl_hess_chol = cholesky(kl_hess)\n",
    "kl_inv_moment_jac = kl_hess_chol.solve_A(moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, kl_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, kl_inv_moment_jac).T\n",
    "timer.toc('inverse_time')\n",
    "print('Done\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return model.objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "timer.tic()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "timer.toc('cg_row_time')\n",
    "\n",
    "num_cg_iterations = optimum_hvp.iter\n",
    "print('Number of iterations: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - kl_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the result to a pickle file for use in subsequent analysis.\n",
    "model.glmm_par.set_free(opt_x)\n",
    "model.prior_par.set_vector(prior_par_vec)\n",
    "\n",
    "run_name = 'production'\n",
    "\n",
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "# Unlike with JSON, numpy arrays can be pickled directly.\n",
    "# Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "pickle_result_dict = logit_glmm.get_pickle_dictionary(model, kl_hess, moment_jac)\n",
    "pickle_result_dict.update(\n",
    "                     { 'run_name': run_name,\n",
    "                       'vb_time': timer.time_dict['vb_time'],\n",
    "                       'hess_time': timer.time_dict['hess_time'],\n",
    "                       'inverse_time': timer.time_dict['inverse_time'],\n",
    "                       'cg_row_time': timer.time_dict['cg_row_time'],\n",
    "                       'num_cg_iterations': num_cg_iterations,\n",
    "                       'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                       'kl_inv_moment_jac': kl_inv_moment_jac,\n",
    "                       'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                       'log_prior_hess': np.squeeze(log_prior_hess) })\n",
    "\n",
    "# Pickle dictionary.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_output_filename)\n",
    "\n",
    "print('Done.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "criteo_experiment_jmlr1951",
   "language": "python",
   "name": "criteo_experiment_jmlr1951"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
