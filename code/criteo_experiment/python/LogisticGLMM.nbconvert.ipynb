{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import json\n",
    "\n",
    "import LinearResponseVariationalBayes as vb\n",
    "import logistic_glmm_lib as logit_glmm\n",
    "import LinearResponseVariationalBayes.SparseObjectives as obj_lib\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "from sksparse.cholmod import cholesky\n",
    "import scipy as sp\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['x', 'beta_prior_info', 'N', 'mu_prior_mean', 'beta_prior_mean', 'mu_prior_info', 'tau_prior_alpha', 'y_group', 'tau_prior_beta', 'y', 'NG', 'K'])\n"
     ]
    }
   ],
   "source": [
    "#analysis_name = 'simulated_data_small'\n",
    "analysis_name = 'criteo_subsampled'\n",
    "\n",
    "git_dir_cmd = subprocess.run(\n",
    "    ['git', 'rev-parse', '--show-toplevel'], stdout=subprocess.PIPE)\n",
    "assert git_dir_cmd.returncode == 0\n",
    "git_dir = git_dir_cmd.stdout.decode(\"utf-8\").strip()\n",
    "\n",
    "data_dir = os.path.join(git_dir, 'code/data')\n",
    "json_filename = os.path.join(data_dir, '%s_stan_dat.json' % analysis_name)\n",
    "y_g_vec, y_vec, x_mat, glmm_par, prior_par = logit_glmm.load_json_data(json_filename)\n",
    "\n",
    "num_gh_points = 4\n",
    "\n",
    "timer = obj_lib.Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize.\n",
    "\n",
    "# Slightly smarter inits would probably improve fit time, but as of now it doesn't\n",
    "# seem worth explaining in the paper.\n",
    "\n",
    "logit_glmm.initialize_glmm_pars(glmm_par)\n",
    "free_par_vec = glmm_par.get_free()\n",
    "init_par_vec = copy.deepcopy(free_par_vec)\n",
    "prior_par_vec = prior_par.get_vector()\n",
    "\n",
    "model = logit_glmm.LogisticGLMM(\n",
    "    glmm_par, prior_par, x_mat, y_vec, y_g_vec, num_gh_points=num_gh_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Newton Trust Region.\n",
      "Iter  0  value:  162411.966974\n",
      "Iter  5  value:  54278.7527672\n",
      "Iter  10  value:  30316.991756\n",
      "Iter  15  value:  27875.0951036\n",
      "Iter  20  value:  23778.0948934\n",
      "Iter  25  value:  23080.3649422\n",
      "Iter  30  value:  23018.7845254\n",
      "Iter  35  value:  22984.4458076\n",
      "Iter  40  value:  22970.0742921\n",
      "Iter  45  value:  22970.0291467\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 22970.029147\n",
      "         Iterations: 46\n",
      "         Function evaluations: 47\n",
      "         Gradient evaluations: 47\n",
      "         Hessian evaluations: 0\n",
      "vb_time: 50.3782479763031 seconds\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Optimize.\n",
    "\n",
    "print('Running Newton Trust Region.')\n",
    "timer.tic()\n",
    "vb_opt = model.tr_optimize(init_par_vec, num_gh_points, gtol=1e-6, maxiter=500)\n",
    "opt_x = vb_opt.x\n",
    "timer.toc('vb_time')\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KL Hessian...\n",
      "\n",
      "Group 0 of 4999.\n",
      "Group 100 of 4999.\n",
      "Group 200 of 4999.\n",
      "Group 300 of 4999.\n",
      "Group 400 of 4999.\n",
      "Group 500 of 4999.\n",
      "Group 600 of 4999.\n",
      "Group 700 of 4999.\n",
      "Group 800 of 4999.\n",
      "Group 900 of 4999.\n",
      "Group 1000 of 4999.\n",
      "Group 1100 of 4999.\n",
      "Group 1200 of 4999.\n",
      "Group 1300 of 4999.\n",
      "Group 1400 of 4999.\n",
      "Group 1500 of 4999.\n",
      "Group 1600 of 4999.\n",
      "Group 1700 of 4999.\n",
      "Group 1800 of 4999.\n",
      "Group 1900 of 4999.\n",
      "Group 2000 of 4999.\n",
      "Group 2100 of 4999.\n",
      "Group 2200 of 4999.\n",
      "Group 2300 of 4999.\n",
      "Group 2400 of 4999.\n",
      "Group 2500 of 4999.\n",
      "Group 2600 of 4999.\n",
      "Group 2700 of 4999.\n",
      "Group 2800 of 4999.\n",
      "Group 2900 of 4999.\n",
      "Group 3000 of 4999.\n",
      "Group 3100 of 4999.\n",
      "Group 3200 of 4999.\n",
      "Group 3300 of 4999.\n",
      "Group 3400 of 4999.\n",
      "Group 3500 of 4999.\n",
      "Group 3600 of 4999.\n",
      "Group 3700 of 4999.\n",
      "Group 3800 of 4999.\n",
      "Group 3900 of 4999.\n",
      "Group 4000 of 4999.\n",
      "Group 4100 of 4999.\n",
      "Group 4200 of 4999.\n",
      "Group 4300 of 4999.\n",
      "Group 4400 of 4999.\n",
      "Group 4500 of 4999.\n",
      "Group 4600 of 4999.\n",
      "Group 4700 of 4999.\n",
      "Group 4800 of 4999.\n",
      "Group 4900 of 4999.\n",
      "Log prior Hessian...\n",
      "\n",
      "hess_time: 62.399622440338135 seconds\n"
     ]
    }
   ],
   "source": [
    "# Get the Hessians at the number of draws used for optimization\n",
    "model.glmm_par.set_free(opt_x)\n",
    "\n",
    "timer.tic()\n",
    "print('KL Hessian...\\n')\n",
    "kl_hess = model.get_sparse_free_hessian(opt_x, print_every_n=100)\n",
    "\n",
    "print('Log prior Hessian...\\n')\n",
    "log_prior_hess = model.get_prior_hess(prior_par.get_vector(), opt_x)\n",
    "\n",
    "moment_jac = model.moment_wrapper.get_moment_jacobian(opt_x)\n",
    "timer.toc('hess_time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving systems...\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:4: CholmodTypeConversionWarning: converting matrix of class csr_matrix to CSC format\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inverse_time: 3.9248642921447754 seconds\n",
      "Done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Solving systems...\\n')\n",
    "timer.tic()\n",
    "from sksparse.cholmod import cholesky\n",
    "kl_hess_chol = cholesky(kl_hess)\n",
    "kl_inv_moment_jac = kl_hess_chol.solve_A(moment_jac.T)\n",
    "lrvb_cov = np.matmul(moment_jac, kl_inv_moment_jac)\n",
    "vb_prior_sens = np.matmul(log_prior_hess, kl_inv_moment_jac).T\n",
    "timer.toc('inverse_time')\n",
    "print('Done\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter  20\n",
      "Iter  40\n",
      "Iter  60\n",
      "Iter  80\n",
      "cg_row_time: 9.471132040023804 seconds\n",
      "Number of iterations:  81\n",
      "1.10014758009e-06\n"
     ]
    }
   ],
   "source": [
    "# Time using conjugate gradient to get a single row of the moment sensitivity.\n",
    "class OptimumHVP(object):\n",
    "    def __init__(self, glmm_par, opt_x, moment_jac):\n",
    "        self.verbose = False\n",
    "        self.print_every = 10\n",
    "        self.reset_iter()\n",
    "        self.opt_x = opt_x\n",
    "        self.moment_jac = moment_jac\n",
    "        self.lo = LinearOperator(\n",
    "            (glmm_par.free_size(), glmm_par.free_size()), self.hvp)\n",
    "        \n",
    "    def reset_iter(self):\n",
    "        self.iter = 0\n",
    "    \n",
    "    def hvp(self, vec):\n",
    "        self.iter += 1\n",
    "        if self.verbose and self.iter % self.print_every == 0:\n",
    "            print('Iter ', self.iter)\n",
    "        return model.objective.fun_free_hvp(self.opt_x, vec)\n",
    "    \n",
    "    def get_moment_sensitivity_row(self, moment_row):\n",
    "        self.reset_iter()\n",
    "        moment_jac_vec = moment_jac[moment_row, :].flatten()\n",
    "        cg_res, info = sp.sparse.linalg.cg(self.lo, moment_jac_vec)\n",
    "        return cg_res, info\n",
    "\n",
    "moment_row = 0\n",
    "optimum_hvp = OptimumHVP(glmm_par, opt_x, moment_jac)\n",
    "optimum_hvp.verbose = True\n",
    "optimum_hvp.print_every = 20\n",
    "timer.tic()\n",
    "cg_res, info = optimum_hvp.get_moment_sensitivity_row(0)\n",
    "timer.toc('cg_row_time')\n",
    "\n",
    "num_cg_iterations = optimum_hvp.iter\n",
    "print('Number of iterations: ', optimum_hvp.iter)\n",
    "\n",
    "print(np.max(np.abs(cg_res - kl_inv_moment_jac[:, moment_row].flatten())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/rgiordan/Documents/git_repos/CovariancesRobustnessVBPaper/code/data/criteo_subsampled_python_vb_results.pkl\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Write the result to a pickle file for use in subsequent analysis.\n",
    "model.glmm_par.set_free(opt_x)\n",
    "model.prior_par.set_vector(prior_par_vec)\n",
    "\n",
    "run_name = 'production'\n",
    "\n",
    "pickle_output_filename = os.path.join(data_dir, '%s_python_vb_results.pkl' % analysis_name)\n",
    "pickle_output = open(pickle_output_filename, 'wb')\n",
    "\n",
    "# Unlike with JSON, numpy arrays can be pickled directly.\n",
    "# Note that it does not seem that you can pickle a sparse Cholesky decomposition.\n",
    "pickle_result_dict = logit_glmm.get_pickle_dictionary(model, kl_hess, moment_jac)\n",
    "pickle_result_dict.update(\n",
    "                     { 'run_name': run_name,\n",
    "                       'vb_time': timer.time_dict['vb_time'],\n",
    "                       'hess_time': timer.time_dict['hess_time'],\n",
    "                       'inverse_time': timer.time_dict['inverse_time'],\n",
    "                       'cg_row_time': timer.time_dict['cg_row_time'],\n",
    "                       'num_cg_iterations': num_cg_iterations,\n",
    "                       'lrvb_cov': np.squeeze(lrvb_cov),\n",
    "                       'kl_inv_moment_jac': kl_inv_moment_jac,\n",
    "                       'vb_prior_sens': np.squeeze(vb_prior_sens),\n",
    "                       'log_prior_hess': np.squeeze(log_prior_hess) })\n",
    "\n",
    "# Pickle dictionary.\n",
    "pickle.dump(pickle_result_dict, pickle_output)\n",
    "pickle_output.close()\n",
    "\n",
    "print(pickle_output_filename)\n",
    "\n",
    "print('Done.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
